ncp <- seq(0, 6, len = 31)
#dt(x, df, ncp, log = FALSE)
pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)
q=0.25
df= 24-2
ncp <- seq(0, 6, len = 1)
#dt(x, df, ncp, log = FALSE)
pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)
require(graphics)
1 - pt(1:5, df = 1)
qt(.975, df = c(1:10,20,50,100,1000))
tt <- seq(0, 10, len = 21)
ncp <- seq(0, 6, len = 31)
ptn <- outer(tt, ncp, function(t, d) pt(t, df = 3, ncp = d))
t.tit <- "Non-central t - Probabilities"
image(tt, ncp, ptn, zlim = c(0,1), main = t.tit)
persp(tt, ncp, ptn, zlim = 0:1, r = 2, phi = 20, theta = 200, main = t.tit,
xlab = "t", ylab = "non-centrality parameter",
zlab = "Pr(T <= t)")
plot(function(x) dt(x, df = 3, ncp = 2), -3, 11, ylim = c(0, 0.32),
main = "Non-central t - Density", yaxs = "i")
require(graphics)
1 - pt(1:5, df = 1)
qt(.985, df = c(1:10,20,50,100,1000))
tt <- seq(0, 10, len = 21)
ncp <- seq(0, 6, len = 31)
ptn <- outer(tt, ncp, function(t, d) pt(t, df = 3, ncp = d))
t.tit <- "Non-central t - Probabilities"
image(tt, ncp, ptn, zlim = c(0,1), main = t.tit)
persp(tt, ncp, ptn, zlim = 0:1, r = 2, phi = 20, theta = 200, main = t.tit,
xlab = "t", ylab = "non-centrality parameter",
zlab = "Pr(T <= t)")
plot(function(x) dt(x, df = 3, ncp = 2), -3, 11, ylim = c(0, 0.32),
main = "Non-central t - Density", yaxs = "i")
require(graphics)
1 - pt(1:5, df = 1)
qt(.985, df = c(1:10,20,50,100,1000))
tt <- seq(0, 10, len = 21)
ncp <- seq(0, 6, len = 31)
ptn <- outer(tt, ncp, function(t, d) pt(t, df = 3, ncp = d))
t.tit <- "Non-central t - Probabilities"
image(tt, ncp, ptn, zlim = c(0,1), main = t.tit)
persp(tt, ncp, ptn, zlim = 0:1, r = 2, phi = 20, theta = 200, main = t.tit,
xlab = "t", ylab = "non-centrality parameter",
zlab = "Pr(T <= t)")
plot(function(x) dt(x, df = 3, ncp = 2), -3, 11, ylim = c(0, 0.32),
main = "Non-central t - Density", yaxs = "i")
1 - pt(1:5, df = 1)
qt(.75, df = c(1:10,20,50,100,1000))
tt <- seq(0, 10, len = 21)
ncp <- seq(0, 6, len = 31)
ptn <- outer(tt, ncp, function(t, d) pt(t, df = 3, ncp = d))
t.tit <- "Non-central t - Probabilities"
image(tt, ncp, ptn, zlim = c(0,1), main = t.tit)
persp(tt, ncp, ptn, zlim = 0:1, r = 2, phi = 20, theta = 200, main = t.tit,
xlab = "t", ylab = "non-centrality parameter",
zlab = "Pr(T <= t)")
plot(function(x) dt(x, df = 3, ncp = 2), -3, 11, ylim = c(0, 0.32),
main = "Non-central t - Density", yaxs = "i")
1 - pt(1:5, df = 1)
qt(.75, df = c(1:10,20,50,100,1000))
tt <- seq(0, 10, len = 21)
ncp <- seq(0, 6, len = 31)
ptn <- outer(tt, ncp, function(t, d) pt(t, df = 3, ncp = d))
1 - pt(1:5, df = 1)
qt(.975, df = c(1:10,20,50,100,1000))
qt(.975, df = c(1:10,20,50,100,1000))
q=0.05
df=22
qt(p, df,        lower.tail = TRUE, log.p = FALSE)
p=0.05
df=22
qt(p, df,        lower.tail = TRUE, log.p = FALSE)
x=1.717144
df=22
dt(x, df, ncp, log = FALSE)
x=1.717144
df=22
dt(x, df, log = FALSE)
x=1.717144
df=22
dt(x, df)
x=1.717144
df=1
dt(x, df)
x=0.48678
df=2
dt(x, df)
x=0.48678
df=2
dt(x, df, TRUE)
x=0.48678
df=2
dt(x, df, FALSE)
x=0.48678
df=22
dt(x, df, FALSE)
install.packages("tdist")
x=
dt(x, df, ncp, log = FALSE)
pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)
qt(p, df, ncp, lower.tail = TRUE, log.p = FALSE)
rt(n, df, ncp)
dt(x, df, ncp, log = FALSE)
pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)
qt(p, df, ncp, lower.tail = TRUE, log.p = FALSE)
rt(n, df, ncp)
?ncp
?td
TDist
?TDist
dt(0.48678, 22, log = FALSE)
dt(0.48678, 22, log = TRUE)
dt(0.48678, 22, log = TRUE, 2)
dt(0.48678, 22, log = FALSE, 2)
dt(0.48678, 22, log = FALSE)
pt(0.48678, 22, lower.tail = TRUE, log.p = FALSE)
qt(0.48678, 22, lower.tail = TRUE, log.p = FALSE)
qt(0.48678, 22, log.p = FALSE)
dt(0.48678, 22, log.p = FALSE)
dt(0.48678, 22, log = FALSE)
dt(0.486781189632292000000, 22, log = FALSE)
dt(0.486781189632292000000, 23, log = FALSE)
dt(0.486781189632292000000, 24, log = FALSE)
pt(0.48678, df, ncp, lower.tail = TRUE, log.p = FALSE)
pt(0.48678, 22, ncp, lower.tail = TRUE, log.p = FALSE)
pt(0.48678, 22, lower.tail = TRUE, log.p = FALSE)
pt(0.48678, 22, lower.tail = FALSE, log.p = FALSE)
pt(0.48678, 22, lower.tail = FALSE, log.p = TRUE)
pt(0.48678, 22, lower.tail = FALSE, log.p = FALSE,2)
pt(0.48678, 22, lower.tail = FALSE, log.p = FALSE)
pt(0.48678, 22, lower.tail = FALSE, log.p = FALSE) * 2
??t.test()
??pt
??t.test
?pt
??t.test
??t.test
q=0.48678
df=22
ncp=0
pt(q, df, ncp, lower.tail = FALSE, log.p = FALSE)
q=0.48678
df=22
ncp=0
pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE)
q=0.48678
df=22
ncp=0
pt(q, df, ncp, lower.tail = FALSE, log.p = FALSE)
q=0.497577699446031000000
df=22
ncp=0
pt(q, df, ncp, lower.tail = FALSE, log.p = FALSE)
q=0.497577699446031000000
df=22
ncp=0
pt(q, df, ncp, lower.tail = FALSE, log.p = FALSE) *2
q=1.703049911646430000000
df=22
ncp=0
pt(q, df, ncp, lower.tail = FALSE, log.p = FALSE) *2
TDist?
?TDist
t.test()
??TDis
q=1.703049911646430000000
df=22
ncp=0
pt(q, df, ncp, lower.tail = FALSE, log.p = FALSE) *2
pt(1.703049911646430000000, 22) *2
TDis
t.test()
TDis()
pt()
?t.test()
q=0.096049824
df=22
ncp=0
pt(q, df, ncp, lower.tail = FALSE, log.p = FALSE)
q=0.096049824
df=22
ncp=0
pt(q, df, ncp, lower.tail = FALSE, log.p = FALSE)*2
summary(object,
test = c("Pillai", "Wilks", "Hotelling-Lawley", "Roy"),
intercept = FALSE, tol = 1e-7, ...)
## Example on producing plastic film from Krzanowski (1998, p. 381)
tear <- c(6.5, 6.2, 5.8, 6.5, 6.5, 6.9, 7.2, 6.9, 6.1, 6.3,
6.7, 6.6, 7.2, 7.1, 6.8, 7.1, 7.0, 7.2, 7.5, 7.6)
gloss <- c(9.5, 9.9, 9.6, 9.6, 9.2, 9.1, 10.0, 9.9, 9.5, 9.4,
9.1, 9.3, 8.3, 8.4, 8.5, 9.2, 8.8, 9.7, 10.1, 9.2)
opacity <- c(4.4, 6.4, 3.0, 4.1, 0.8, 5.7, 2.0, 3.9, 1.9, 5.7,
2.8, 4.1, 3.8, 1.6, 3.4, 8.4, 5.2, 6.9, 2.7, 1.9)
Y <- cbind(tear, gloss, opacity)
rate     <- gl(2,10, labels = c("Low", "High"))
additive <- gl(2, 5, length = 20, labels = c("Low", "High"))
fit <- manova(Y ~ rate * additive)
summary.aov(fit)             # univariate ANOVA tables
summary(fit, test = "Wilks") # ANOVA table of Wilks' lambda
summary(fit)                # same F statistics as single-df terms
install.packages(c("pillar", "rlang", "Rmixmod", "timeDate"))
.path.package(...)
# Defunct in 1.x
Version()
provide(package)
.Provided
category(...)
print.anova.glm(.)
print.anova.lm(.)
print.tabular(.)
print.plot(.)
save.plot(.)
system.test(.)
getenv(...)
read.table.url(url, method, ...)
scan.url(url, file = tempfile(), method, ...)
source.url(url, file = tempfile(), method, ...)
httpclient(url, port = 80, error.is.fatal = TRUE,
check.MIME.type = TRUE, file = tempfile(),
drop.ctrl.z = TRUE)
parse.dcf(text = NULL, file = "", fields = NULL,
versionfix = FALSE)
.Alias(expr)
print.ordered(.)
.Dyn.libs
.lib.loc
machine()
Machine()
Platform()
restart()
printNoClass(x, digits = NULL, quote = TRUE, na.print = NULL,
print.gap = NULL, right = FALSE, ...)
codes(x, ...)
codes(x, ...) <- value
x =9
r = 8
shortestpath?
install.packages("irace")
#######################################################################
# This example illustrates how to tune the parameters of the simulated
# annealing algorithm (SANN) provided by the optim() function in the
# R base package.  The goal in this example is to optimize instances of
# the following family:
# f(x) = lambda * f_rastrigin(x) + (1 - lambda) * f_rosenbrock(x)
# where lambda follows a normal distribution whose mean is 0.9 and
# standard deviation is 0.02. f_rastrigin and f_rosenbrock are the
# well-known Rastrigin and Rosenbrock benchmark functions (taken from
# the cmaes package). In this scenario, different instances are given
# by different values of lambda.
#######################################################################
## First we provide an implementation of the functions to be optimized:
f_rosenbrock <- function (x) {
d <- length(x)
z <- x + 1
hz <- z[1:(d - 1)]
tz <- z[2:d]
s <- sum(100 * (hz^2 - tz)^2 + (hz - 1)^2)
return(s)
}
f_rastrigin <- function (x) {
sum(x * x - 10 * cos(2 * pi * x) + 10)
}
## We generate 200 instances (in this case, weights):
weights <- rnorm(200, mean = 0.9, sd = 0.02)
## On this set of instances, we are interested in optimizing two
## parameters of the SANN algorithm: tmax and temp. We setup the
## parameter space as follows:
parameters.table <- '
tmax "" i (1, 5000)
temp "" r (0, 100)
'
## We use the irace function readParameters to read this table:
parameters <- readParameters(text = parameters.table)
## Next, we define the function that will evaluate each candidate
## configuration on a single instance. For simplicity, we restrict to
## three-dimensional functions and we set the maximum number of
## iterations of SANN to 5000.
target.runner <- function(experiment, scenario)
{
instance <- experiment$instance
configuration <- experiment$configuration
D <- 3
par <- runif(D, min=-1, max=1)
fn <- function(x) {
weight <- instance
return(weight * f_rastrigin(x) + (1 - weight) * f_rosenbrock(x))
}
res <- stats::optim(par,fn, method="SANN",
control=list(maxit=5000
, tmax = as.numeric(configuration[["tmax"]])
, temp = as.numeric(configuration[["temp"]])
))
## New output interface in irace 2.0. This list may also contain:
## - 'time' if irace is called with 'maxTime'
## - 'error' is a string used to report an error
## - 'outputRaw' is a string used to report the raw output of calls to
##   an external program or function.
## - 'call' is a string used to report how target.runner called the
##   external program or function.
return(list(cost = res$value))
}
## We define a configuration scenario by setting targetRunner to the
## function define above, instances to the first 100 random weights, and
## a maximum budget of 1000 calls to targetRunner.
scenario <- list(targetRunner = target.runner,
instances = weights[1:100],
maxExperiments = 1000,
# Do not create a logFile
logFile = "")
## We check that the scenario is valid. This will also try to execute
## target.runner.
checkIraceScenario(scenario, parameters = parameters)
## We are now ready to launch irace. We do it by means of the irace
## function. The function will print information about its
## progress. This may require a few minutes, so it is not run by default.
tuned.confs <- irace(scenario = scenario, parameters = parameters)
## We can print the best configurations found by irace as follows:
configurations.print(tuned.confs)
## We can evaluate the quality of the best configuration found by
## irace versus the default configuration of the SANN algorithm on
## the other 100 instances previously generated.
## To do so, first we apply the default configuration of the SANN
## algorithm to these instances:
test <- function(configuration)
{
res <- lapply(weights[101:200],
function(x) target.runner(
experiment = list(instance = x,
configuration = configuration),
scenario = scenario))
return (sapply(res, getElement, name = "cost"))
}
default <- test(data.frame(tmax=10, temp=10))
## We extract and apply the winning configuration found by irace
## to these instances:
tuned <- test (removeConfigurationsMetaData(tuned.confs[1,]))
## Finally, we can compare using a boxplot the quality obtained with the
## default parametrization of SANN and the quality obtained with the
## best configuration found by irace.
boxplot(list(default = default, tuned = tuned))
#######################################################################
# This example illustrates how to tune the parameters of the simulated
# annealing algorithm (SANN) provided by the optim() function in the
# R base package.  The goal in this example is to optimize instances of
# the following family:
# f(x) = lambda * f_rastrigin(x) + (1 - lambda) * f_rosenbrock(x)
# where lambda follows a normal distribution whose mean is 0.9 and
# standard deviation is 0.02. f_rastrigin and f_rosenbrock are the
# well-known Rastrigin and Rosenbrock benchmark functions (taken from
# the cmaes package). In this scenario, different instances are given
# by different values of lambda.
#######################################################################
## First we provide an implementation of the functions to be optimized:
f_rosenbrock <- function (x) {
d <- length(x)
z <- x + 1
hz <- z[1:(d - 1)]
tz <- z[2:d]
s <- sum(100 * (hz^2 - tz)^2 + (hz - 1)^2)
return(s)
}
f_rastrigin <- function (x) {
sum(x * x - 10 * cos(2 * pi * x) + 10)
}
## We generate 200 instances (in this case, weights):
weights <- rnorm(200, mean = 0.9, sd = 0.02)
## On this set of instances, we are interested in optimizing two
## parameters of the SANN algorithm: tmax and temp. We setup the
## parameter space as follows:
parameters.table <- '
tmax "" i (1, 5000)
temp "" r (0, 100)
'
## We use the irace function readParameters to read this table:
parameters <- readParameters(text = parameters.table)
## Next, we define the function that will evaluate each candidate
## configuration on a single instance. For simplicity, we restrict to
## three-dimensional functions and we set the maximum number of
## iterations of SANN to 5000.
target.runner <- function(experiment, scenario)
{
instance <- experiment$instance
configuration <- experiment$configuration
D <- 3
par <- runif(D, min=-1, max=1)
fn <- function(x) {
weight <- instance
return(weight * f_rastrigin(x) + (1 - weight) * f_rosenbrock(x))
}
res <- stats::optim(par,fn, method="SANN",
control=list(maxit=5000
, tmax = as.numeric(configuration[["tmax"]])
, temp = as.numeric(configuration[["temp"]])
))
## New output interface in irace 2.0. This list may also contain:
## - 'time' if irace is called with 'maxTime'
## - 'error' is a string used to report an error
## - 'outputRaw' is a string used to report the raw output of calls to
##   an external program or function.
## - 'call' is a string used to report how target.runner called the
##   external program or function.
return(list(cost = res$value))
}
## We define a configuration scenario by setting targetRunner to the
## function define above, instances to the first 100 random weights, and
## a maximum budget of 1000 calls to targetRunner.
scenario <- list(targetRunner = target.runner,
instances = weights[1:100],
maxExperiments = 1000,
# Do not create a logFile
logFile = "")
## We check that the scenario is valid. This will also try to execute
## target.runner.
checkIraceScenario(scenario, parameters = parameters)
## We are now ready to launch irace. We do it by means of the irace
## function. The function will print information about its
## progress. This may require a few minutes, so it is not run by default.
tuned.confs <- irace(scenario = scenario, parameters = parameters)
## We can print the best configurations found by irace as follows:
configurations.print(tuned.confs)
## We can evaluate the quality of the best configuration found by
## irace versus the default configuration of the SANN algorithm on
## the other 100 instances previously generated.
## To do so, first we apply the default configuration of the SANN
## algorithm to these instances:
test <- function(configuration)
{
res <- lapply(weights[101:200],
function(x) target.runner(
experiment = list(instance = x,
configuration = configuration),
scenario = scenario))
return (sapply(res, getElement, name = "cost"))
}
default <- test(data.frame(tmax=10, temp=10))
## We extract and apply the winning configuration found by irace
## to these instances:
tuned <- test (removeConfigurationsMetaData(tuned.confs[1,]))
## Finally, we can compare using a boxplot the quality obtained with the
## default parametrization of SANN and the quality obtained with the
## best configuration found by irace.
boxplot(list(default = default, tuned = tuned))
f_rosenbrock <- function (x) {
d <- length(x)
z <- x + 1
hz <- z[1:(d - 1)]
tz <- z[2:d]
s <- sum(100 * (hz^2 - tz)^2 + (hz - 1)^2)
return(s)
}
f_rastrigin <- function (x) {
sum(x * x - 10 * cos(2 * pi * x) + 10)
}
f_rosenbrock <- function (x) {
d <- length(x)
z <- x + 1
hz <- z[1:(d - 1)]
tz <- z[2:d]
s <- sum(100 * (hz^2 - tz)^2 + (hz - 1)^2)
return(s)
}
f_rastrigin <- function (x) {
sum(x * x - 10 * cos(2 * pi * x) + 10)
}
View(f_rastrigin)
install.packages("osmar")
file <- system.file("extdata", "kaufstr.xml", package = "osmar")
raw <- readLines(file)
kaufstr <- as_osmar(xmlParse(raw))
kaufstrGraph <- as_igraph(kaufstr)
file <- system.file("extdata", "kaufstr.xml", package = "osmar")
raw <- readLines(file)
kaufstr <- as_osmar(xmlParse(raw))
kaufstrGraph <- as_igraph(kaufstr)
file <- system.file("extdata", "kaufstr.xml", package = "osmar")
raw <- readLines(file)
kaufstr <- as_osmar(xmlParse(raw))
kaufstrGraph <- as_igraph(kaufstr)
as_osmar(xmlParse(raw))
xmlParse(raw)?
## Not run:
# Load data
data("com")
### osrmTable ###
# Inputs are data frames
# Travel time matrix
distCom <- osrmTable(loc = com[1:50, c("comm_id","lon","lat")])
# First 5 rows and columns
distCom$durations[1:5,1:5]
# Travel time matrix with different sets of origins and destinations
distCom2 <- osrmTable(src = com[1:10,c("comm_id","lon","lat")],
dst = com[11:20,c("comm_id","lon","lat")])
# First 5 rows and columns
distCom2$durations[1:5,1:5]
# Inputs are SpatialPointsDataFrames
distCom <- osrmTable(loc = src)
# First 5 rows and columns
distCom$durations[1:5,1:5]
# Travel time matrix with different sets of origins and destinations
distCom2 <- osrmTable(src = src, dst = dst)
# First 5 rows and columns
distCom2$durations[1:5,1:5]
### osrmRoute ###
# Travel path between points
route <- osrmRoute(src = com[1, c("comm_id", "lon","lat")],
dst = com[15, c("comm_id", "lon","lat")])
# Display the path
plot(com[c(1,15),3:4], asp =1, col = "red", pch = 20, cex = 1.5)
points(route[,1:2], type = "l", lty = 2)
text(com[c(1,15),3:4], labels = com[c(1,15),2], pos = 2)
shiny::runApp('E:/PROJECT/KR Project/devcs/Shiny_01')
